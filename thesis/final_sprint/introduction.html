<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <title></title>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="date" content="" />

<!-- personal style options -->

	<style type="text/css">
		div[id="body_text"] {
			width: 61.8%;
			float: left;
		}

		#footer {
		
		}

		/* we will need to add abbr's automatically */
		abbr { letter-spacing: 0.1em }

		body {
			font-family : "Lib-Sans-R", serif;
		}
		
		
		
		p {
			text-align: left;
			
		}

		em {
			font-family : "Lib-Sans-I";
		}

		h1 {
			font-family : "Lib-Serif-R";
		}

		h1[class="title"] {
			font-size : 2.8em;
			color : #910A00;
			right: 85%;
		}

		h1[class="author"] {
			font-size : 1.8em;
		}

		h1[class="date"] {
			font-size : 1.3em;
		}

		h2 {
			font-family : "Lib-Serif-R"
		}

		div[class="title_section"] {
			padding-bottom : 4em; 
		}

		@font-face {
			font-family : "Lib-Serif-R";
			src : url(ttf/LiberationSerif-Regular.ttf) format("truetype");
		}

		@font-face {
			font-family : "Lib-Sans-R";
			src : url(ttf/LiberationSans-Regular.ttf) format("truetype");
		}

		@font-face {
			font-family : "Lib-Sans-I";
			src : url(ttf/LiberationSans-Italic.ttf) format("truetype");
		}
	</style>

<!-- end personal style segment -->

</head>
<body>
<div id="body_text">
<div id="introduction"
><h2
  ><span class="header-section-number"
    >0.1</span
    > Introduction</h2
  ><p
  >Today's new media theory increasingly invokes <em
    >materiality</em
    > as a significant, perhaps even <em
    >the</em
    > significant, mode of investigating digital objects and the media through which they are delivered. This thesis questions such a centrality of materiality through a practice-based, process-oriented approach. <em
    >Process</em
    > is proposed as the atomic unit of that which new media theory investigates. This is true on a formal material level: applications run as either as individual process or as assemblages of process which are managed by an operating system and through which the application's code is accomplishes all of its tasks, from memory and access to algorithmic execution on the central processing unit. A process-oriented approach will be shown to provide superior methodologies for engaging with and understanding software than material analysis alone provides. For instance, certain problematics within Lev Manovich's concept of 'media hybridity' will be resolved by a re-orientation towards process (Manovich 2008). Process also allows a fresh perspective for examining human-digital relations. Human processes and digital processes are seen as inextricably intertwined, leaving any discussion of digital process that excludes relevant dimensions of human process necessarily unfinished.</p
  ><p
  >=== FRESH ===</p
  ><p
  >In this introduction, I will first briefly re-trace the vectors of medium theory as they have developed since the introduction of 'new media' as an academic institution. Such re-tracing necessarily begins with McLuhan, as his theory is intrinsic to one of the earliest theoretical frameworks of new media, the <em
    >remediation</em
    > model of Jay David Bolter and Richard Grusin. This framework was eventually superceded by a discipline-wide turn towards investigations of materiality and medium specificity, spearheaded by the work of N. Katherine Hayles. Finally, Lev Manovich's manuscript <em
    >Software takes command</em
    > provides concepts of <em
    >media hybridity</em
    > and <em
    >deep remixability</em
    >. Throughout this swath of theory is woven an intrinsic focus on the <em
    >material</em
    > modes of media. Media hybridity, for instance, relies on a medium having a specific dimensionality that is enlarged or otherwise augmented through hybridization with other mediums. In a significant example, the dimension of typography obtains velocity and physicality as it enters the 3D void of the After Effects window. I pose the following question to this explanation [WHUT WASS IT AGGIN&gt;&gt;??]. Rather than 'dimensionality,' I propose that we conceptualize these hybridizations as generating new levels of metapotentiality. This is a transposition of Gilbert Simondon's language of ontogenesis into new media discourse. Simondon utilizes the ideas of metastability and metapotential to describe active forms of those concepts: a metastability is likened to a substrate in which massive activity occurs. One example is a fluid suspension that happens to contain ideal conditions for crystalization: the metastability of the suspension drives its crystalization, and crystalization is the actualization of the suspension's metapotential. Yet crystalization is a singular process, a form of individuation for which identical crystals are said not to exist in nature. The metapotential of each substrate is fulfilled uniquely. And in natural or otherwise unbounded systems, crystals are often on-going processes of <em
    >individuation</em
    >---Simondon's term for the movement of a metastability through the courses of its own metapotential. This thesis proposes that grammars are a key factor of enabling hybridization. Hybridization, in turn, expands and extends the metapotentials of involved processes. Thus, grammars are crucial mechanisms through which the metastability expands along its metapotential.</p
  ><p
  >The method proposed to demonstrate these points is two-fold. The first is an analytic approach---the modes of operation of designers themselves are examined. Starting from the proprietary Mac OS X operating system, described here as a unique and powerful example of <em
    >process hybridity</em
    >, we progress to a discussion of the operations of designers as constrained by FLoSS (Free/Libre/open/Source Software). The second aspect of the method is a detailed interrogation of actual practice in the form of <em
    >digital typesetting</em
    >. This topic was chosen for several reasons. The first is a general lack of focus on the processes behind typesetting among new media theory---while the surfaces of text have been investigated in numerous ways (Bolter 2001; Fuller 2000), there has been a general lack of concern (or capacity) regarding the underlying processes of text in the metamedium (computers). This is especially evidenced as regards the <em
    >command line interface</em
    >, a realm where text becomes kinetic. Yet I found that very little theory has been written regarding the command-line, despite its place as the historical interface (once contemporary with batch punch cards) by which digital processes were initiated. Far from being obsolete, both Microsoft and Apple ship command line interfaces within their operating systems. In Microsoft´s case, significant money has been spent developing a new grammar and implementing new functionalities into their modern command line implementation Powershell (as opposed to the grammar and functionalities of DOS).</p
  ><p
  >The second reason for choosing typesetting is the supposed lack of media hybridity of typesetting--according to Manovich's definitions of the terms, typesetting has failed to move beyond 'multimedia' to a state of 'media hybridity' (this is opposed to typography, which undoubtedly has) (2008: 86). Media hybridity is Manovich´s formulation of the increasingly common ¨sharing of languages¨ between media. When media share language, they develop new dimensions (2008: 86). Language, then, demonstrates its capacity for modulation in a new context. While the proposition that ¨language can add dimensions to things¨ may at first consideration seem a bit too obvious for stating out loud, the kinetic properties of language within the context of the metamedium--that the code enabling the language sharing that enables media hybridity is <em
    >itself made of language and made executable by language</em
    >--seem to beg for consideration. Whereas much of the new media discourse relating to changes in media trends toward contemplating fast-paced visual cultures such as video games and cinema, this thesis aims to take the opportunity to contemplate the much slower-moving medium of text. This contemplation of screenic text leads to questions about the nature of media within a medium as well as to the introduction of a conception of processual hybridity that both underpins and exceeds the dynamics of media hybridity.</p
  ><p
  >The third aspect is the allowance of a truly reflexive investigation in which multiple processes of digital typesetting are utilized to generate the thesis itself. This provides a means to integrate the process-oriented perspective into a software study of FLoSS typesetting software. Not only this, it provides a means to attempt what could be considered a <em
    >refractional</em
    > methodology. Inspired by Gilbert Simondon´s adoption of the language of chemistry in the formulation of <em
    >transduction</em
    > within his theory of ontogenesis, this thesis can be viewed as a distinct crystallization process, the composition of a whole from the process of that whole´s unfolding. The applicability of Simondon´s ontogenesis to matters of generative design will be interrogated in contrast to Jay David Bolter and David Grusin´s remediation theory (Bolter and Grusin 1996; Bolter 2001). Ontogenesis, albeit without Simondon, has already proven an effective angle for approaching Web 2.0 platforms (Langlois, McKelvey, Elmer, and Werbin 2009). Here the description of this thesis´own workflow will demonstrate Simondon´s ontogenesis as making unique contributions to the process-oriented perspective which this thesis attempts to invoke and instantiate.</p
  ><p
  >The fourth is the simple fact that screenic text has not been interrogated on a <em
    >subtextual</em
    > level---surface analysis of text (and hypertext) have driven the discourse of screenic text in new media.</p
  ></div
><div id="screens"
><h2
  ><span class="header-section-number"
    >0.2</span
    > Screens</h2
  ><p
  >As digital typesetting provides the focus for the application of the process-oriented perspective, the point of origin is necessarily that of the screen. Information transmission is increasingly screen-based, a fact that only intensifies with the exponentializing ubiquity of mobile devices such as the iPhone. The long-awaited advent of cheap &quot;tablet&quot; computers and e-readers is also now at hand. These devices may all be seen as mediums for <em
    >screenic processes</em
    > in that their entire configuration and all of its computation exists to serve as the basis for screenic interactions with <em
    >human processes</em
    >. These phrasings introduce the perceptual angle attendent with this thesis, namely the centering of <em
    >process</em
    > as the atomic unit of what is discussed in new media theory. The term <em
    >screenic</em
    > simply means 'screen-based,' or (perhaps) 'screen-native.' It is analagous to 'printed.'</p
  ><p
  >One way to define screens is in terms of their interactivity. Some screens, such as television screens, offer very limited interactivity: the choice of content. This choice itself can be constrained by varying degrees, such as the number of available channels and playback formats (VHS, DVD, Xvid, etc.), even to the point of disappearing (in the case of many televisions that appear in public spaces).<sup
    ><a href="#fn1" class="footnoteRef" id="fnref1"
      >1</a
      ></sup
    > The medium of the remote control should not be underestimated in its effects on human processes, to say nothing of the screens at which they are aimed. Indeed, they drive the interactivity of the video game consoles, an interactivity that clearly represents the cultural cutting edge of what a television screen can offer.</p
  ><p
  >The computer screen, on the other hand, is defined by its seemingly limitless degree of interactivity. Remote controls can be run as screenic processes and can not only change television channels--processes on remote systems can be controlled with similar ease. Indeed, the entire screenic composition of one computer can be controlled over a network by a second computer using included, or easy to obtain, applications. Furthermore, the very interfaces to the screen (keyboards and mice) are examples of remote controls in cases where the screen has not itself become its own remote control (touch-screen devices). Typically the only element of a computer screen that the user does not effectively control are the structure and visual language of an operating system's graphical user interface (GUI). Even this, however, is generally accomplishable by a significantly informed user. In the case of GNU/Linux the task is not only accomplishable: in the case of a &quot;from scratch&quot; installation,<sup
    ><a href="#fn2" class="footnoteRef" id="fnref2"
      >2</a
      ></sup
    > the user is literally forced to make a choice of GUI structure and visual styling. Microsoft has generally shipped their operating systems with multiple choices for widget<sup
    ><a href="#fn3" class="footnoteRef" id="fnref3"
      >3</a
      ></sup
    > presentation, including re-mediations of widgets from previous versions of Windows. Users also developed Apple, however, maintains strict control of widget presentation, especially on their mobile devices.</p
  ></div
><div id="screens-as-material-screens-as-process"
><h2
  ><span class="header-section-number"
    >0.3</span
    > Screens as material, screens as process</h2
  ><p
  >Screens offer an ideal point of juxtaposition between the material and processual frames. From a material view, the very formulation of &quot;screens&quot; as <em
    >the</em
    > interface between humans and computers is problematic: what of the interfaces that have been developed to work around instances of blindness or other [disabilities] that prohibit visually screenic interaction?</p
  ><p
  >From a processual orientation, the question becomes: how do interactions between humans and computers resolve themselves? The answer returns in the form of the <em
    >available</em
    > remote controls and the <em
    >available</em
    > response interfaces. The next step might be to investigate the degree of variance between these availabilities, and whether they problematize any umbrella-classification. While it would be <em
    >insensible</em
    > to argue that material differences in inputs and outputs can--or do--not lead to a huge amount of variation between experiences within humans. Such variation is likely to occur in differentials. That is to say, the spectrum of possible feedback occurs at the level of the human individual---one's experiences are functionally irrepresentable without translation of some kind. [We can choose to call these translations mediums, or we can choose to call these processes.]</p
  ><p
  >At this point the question becomes, then, whether it is necessary to instantiate these inherent divergences in every evocation of a broad level discussion of input and output mechanisms or whether the inherent, <em
    >core</em
    > similarity between them all remains that in all instances they serve as <em
    >the point of contact</em
    > between human and digital processes. Does it make a processual difference if the output technology is a braille screen or an LCD screen? Only inasmuch as to what degree the process being examined is unique to, or highlights differences between, one or the other. From a discursive level, <em
    >controls</em
    > and <em
    >screens</em
    > can capture the essence of these dual &quot;action spaces&quot; that together form the single point of contact between human and digital process.</p
  ><p
  >Is it possible to remediate of the term screen into discussions of previous mediums? For instance could one speak of the &quot;screen&quot; of a newspaper or the &quot;screen&quot; of a cave wall? What about the &quot;screen&quot; of a radio? From a linguistic-conceptual perspective the final example certainly pushes the limits. From a process perspective, though, the presence of the radio/what it is playing/what listening choices are available/how and to what degree does the hardware support frequency tuning: these questions can all be conceived in terms of 'control' and 'screen.' The sounds of a radio do emit, after all, from the vibrations of a stretched membrane.</p
  ><p
  >This thesis proposes a conceptual-linguistic shift in the discussions of screens as the <em
    >site of discourse</em
    > through which digital processes yield the results of their execution. Likewise, the remote control, or simply <em
    >control</em
    >, is the site of discourse through which which human processes instigate and extend into the digital. There is no removing or reducing of this dyadic assemblage---even when the control and the screen are literally fused (as in most contemporary smartphones) the distinction between <em
    >control</em
    > and <em
    >screen</em
    > holds on both a conceptual and material level. Conceptually, human process still extends through the control into digital process, which still produces feedback through the screen. Materially, the screen is a Liquid Crystal Display driven by a graphics card that interfaces with coded drivers and display subsystems in the device's operating system. The control, on the other hand, is the glass suspended over the LCD which, through one or more of the multitude of available technical solutions for the process, reads point(s) of contact, pressure, and vectors (velocity and direction) of movement.</p
  ></div
><div id="from-screens-to-text"
><h2
  ><span class="header-section-number"
    >0.4</span
    > From Screens to Text</h2
  ><p
  >To discuss computer screens one must necessarily engage with the concept of <em
    >interface</em
    >, a topic that rightfully occupies a great deal of current new media discourse. Interface, then, represents one point of departure from our origin. While interfaces often utilize many visual metaphors (most of them inherited from the work done developing the first GUI at Xerox's Palo Alto Advanced Research Lab (PARC) in the 1970s), there are yet few computer interfaces that do not rely on text as their dominant mechanism for organizing and presenting a program's internal capabilities to a user. (Mobile screens, on the other hand, increasingly display developing trends of icon-only design, though the web browser remains a popular application). Despite the success of the GUI over the text-only command-line interface (CLI), text remains central to contemporary experiences of computer screens.</p
  ><p
  >The command line is seen as a space of contestation for traditional modes of media analysis. Remediation, for instance, will be demonstrated as inappropriate for discussing the CLI. As Google has just recently released a command line interface for interacting with Google services, I believe a discussion of the command line is essential for new media (Holt and Miller 2010).</p
  ><p
  >(Unfortunate to note, this historiographic aspect is still <strong
    >'to-do'</strong
    >:</p
  ><p
  >The centrality of text to the experience of computer screens represents the main avenue by which we proceed from the origin, constituting a trunk from which many additional concerns fork away and then face examination. The arguments of the paper are augmented by the inclusion of a historiography of digital typesetting. Engaging critically with the history of <em
    >software itself</em
    > is considered a requisite for responsible software studies: a full range of influences (economic, cultural, technological) should be considered in the re-telling of a given processual unfolding. In this aspect of focus, it extends Lev Manovich's admirable positioning of history as central to a software study by broadening the scope of historical considerations.<sup
    ><a href="#fn4" class="footnoteRef" id="fnref4"
      >4</a
      ></sup
    > Inspiring this enagement is the work of Robin Kinross, whose <em
    >Modern typography: an essay in critical history</em
    > is one of but a few texts covering a history of typography to adequately engage with the influence of factors outside of that field on the field itself (Kinross 2004). By integrating a critical history of digital typesetting with a process perspective, an equilibrium between human and digital processes will be illustrated.</p
  ><div id="recognizing-the-ontogenesis-in-generativity"
  ><h3
    ><span class="header-section-number"
      >0.4.1</span
      > Recognizing the Ontogenesis in Generativity</h3
    ><p
    >In his text <em
      >The Position of the Problem of Ontogenesis</em
      >, Simondon writes,</p
    ><p
    >By transduction we mean an operation--physical, biological, mental, social--by which an activity propagates itself from one element to the next, within a given domain, and founds this propagation on a structuration of the domain that is realized from place to place: each area of the constituted structure serves as the principle and the model for the next area, as a primer for its constitution, to the extent that the modification expands progresively at the same time as the structuring operation. (Simondon 2009: 11).</p
    ><p
    >Note the distinct lack of 'computational' in Simondon's list of operations. Written prior to the advent of Manovich's formulation of the age of cultural computing, this absence might simply be read as a matter of temporal context. Nevertheless, Simondon's solution to the ontogenesis problematic provides a framework for describing digital processes of a generative nature.</p
    ><p
    >This leads to another important element of this thesis, one that runs throughout the entirety of itself---the underlying processes of presentation required to 'typeset' the text itself. Through the utilization of FLoSS software, multiple output formats will be not only be investigated but also materially instantiated through a designed mechanism of process--a <em
      >processual hybridity</em
      >. These output formats represent two of the top formats currently used to manage and display texts digitally: HTML and PDF.</p
    ><p
    >The process(es) of their generation offers an attempt at mapping Gilbert Simondon's language of ontogenesis onto file format translation or, to begin the project immediately, <em
      >individuation</em
      >. Coupled with Simondon's individuation is this concept of <em
      >transduction</em
      >. Repurposed from the language of chemistry, Simondon's metaphorically images transduction with the example of a substrate--swelling with <em
      >metapotential</em
      >--that crystallizes. The final formation is the substrate fulfilling this metapotential, a fulfillment that arises only through an unpredictable unfolding involving emergent factors. (The language of chemistry was likewise appropriated for the term 'interface' (Cramer and Fuller 2008: 149)).</p
    ><p
    >Through this mapping I hope to provide a convincing argument for shared properties between what I am calling process and individuation, and between transduction and what I am calling instantiation.</p
    ><p
    >This relates with the increasingly generative nature of contemporary design. All of which are generated from a plain-text file whose syntax conforms to a format standard called 'markdown.' The polycephalous nature of <em
      >the text itself</em
      > thus demands further branching into a discussion of formats. What are the attributes of the class of process to which formats belong? Formats are seen as stable, yet they move like glass (or glaciar) in the nano-magnitudes of the digital. Formats provide another point of contrast between process and material perceptual orientations.</p
    ><p
    >The discussion of generativity provides further means to demonstrate the equilibrium of human and digital processes. Analyzed materially, these processes are chunks of code electronically lifted from hard drive platters, loaded into system memory, and then executed via the assemblage of chips on the computer's motherboard by way of instructions from the operating system currently residing as a mass of memory heaps in RAM chips. Analyzed <em
      >processually</em
      >, however, these digital processes are properly seen as deriving from interactions with human beings. That is to say, digital and human processes are intimately intertwined, from the design of their physical landscape of execution (microcircuitry) to the instructions derived from the user. From a process angle the computer becomes something of an external nervous system, extending and modifying the realm of human potentiality even as it surpasses the capacity of a single mind to functionally comprehend the entirety of its workings.<sup
      ><a href="#fn5" class="footnoteRef" id="fnref5"
	>5</a
	></sup
      ></p
    ></div
  ><div id="print-is-static-code-is-process"
  ><h3
    ><span class="header-section-number"
      >0.4.2</span
      > Print is static, code is process</h3
    ><p
    >The flat/deep distinction proposed by Hayles is, by its formualation, material. Problematizing this material focus is the interwoven history of text and code: the lens of typesetting allows us to focus on a unique intersection of the two. As the historiographic case will demonstrate, typesetting is a <em
      >non-reducible</em
      > process (NP-Complete). This non-reducibility of typesetting reflects the non-reducibility of computational processing of language, as well as the non-reducibility of language, as signifier, into that which is actually signified. This &quot;turtles all the way down&quot; scenario has intriguing implications from a process perspective as we investigate the methods that have been developed in order to work around this non-reducibility.</p
    ><p
    >When Hayles states that &quot;materiality thus cannot be specified in advance; rather it occupies a borderland--or better, performs as connective tissue,&quot; she is provisionally correct (Hayles 2004: 72). However, this metaphor-ization of process is exemplary of new media practices: reference the complex with an abstract metaphor, obscuring complex and important dynamics with a metaphor. The metaphor works, to be sure. One could even consider it an ideal formulation. At issue is the fact that this borderland is not discussed in a technically correct manner.</p
    ></div
  ></div
><div id="remote-controls"
><h2
  ><span class="header-section-number"
    >0.5</span
    > Remote Controls</h2
  ><p
  >I think it may be reasonable to take the remote control and use it to create a metaphor for all human-computer interaction.</p
  ><p
  >Every digital process has, at its origin, a human. The rate of computation has increased the impact of human-digital processes in that the results deliver their results faster. The results will either match the intentions of the originating human process, or they will not. In the second case we can find the first evidence of the effects of digital process on human process: <em
    >the code behind the digital process will be re-arranged in an attempt to deliver an output that satisfies the intention of the human processes.</em
    > Whether this modulation of the executed code is through sliders/input boxes/etc within a GUI interface or through direct reworking of the source code itself, the effect is the same: the code executed has been re-configured according to the goal of human process. The result(s) of the digital process, experienced through a screen, can match, exceed, or fail this goal. In turn, human process is effected and the next move is made according to new goals or revised digital processes.</p
  ></div
><div class="footnotes"
><hr
   /><ol
  ><li id="fn1"
    ><p
      >Mobile devices are beginning to ship IR transeivers with full hardware access through software. That is, the <em
	>entire potential</em
	> of the IR spectrum is available to them. <a href="#fnref1" class="footnoteBackLink" title="Jump back to footnote 1">↩</a></p
      ></li
    ><li id="fn2"
    ><p
      >Such as is demanded by no-frills distributions such as Gentoo and ArchLinux, where manual installation and configuration of a GUI is required for use. <a href="#fnref2" class="footnoteBackLink" title="Jump back to footnote 2">↩</a></p
      ></li
    ><li id="fn3"
    ><p
      >A widget is the technical term for a GUI element. Scrollbars, titlebars, menus, and close/minimize/maximize buttons are widgets attached to most of the &quot;windows&quot; that appears on any given GUI-driven computer. <a href="#fnref3" class="footnoteBackLink" title="Jump back to footnote 3">↩</a></p
      ></li
    ><li id="fn4"
    ><p
      ><strong
	>Note:</strong
	> This work largely remains unfinished in this draft, as it became apparent that I needed to work back through more discussions of basic infrastructural elements such as operating systems in order to fully describe the assemblage of process upon which computer-based design is situated.) <a href="#fnref4" class="footnoteBackLink" title="Jump back to footnote 4">↩</a></p
      ></li
    ><li id="fn5"
    ><p
      >The chips produced by Intel, for example, are too complex for any single person to ever hope to entirely understand. <a href="#fnref5" class="footnoteBackLink" title="Jump back to footnote 5">↩</a></p
      ></li
    ></ol
  ></div
>
</div>
</body>
</html>

